{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"introduction_bacmman_data.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPoTlNlvdNrmEMmJSnsMLwx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EBv6eeQpRvJt","colab_type":"text"},"source":["# Introduction on the real BACMMAN dataset"]},{"cell_type":"code","metadata":{"id":"7FJcZqdaRuJX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595958368890,"user_tz":-120,"elapsed":12045,"user":{"displayName":"H V","photoUrl":"","userId":"04112076308917049663"}},"outputId":"71e0acb0-5f0b-43b6-a16d-c92a20b042c7"},"source":["# mount drive\n","from google.colab import drive\n","ROOT = '/content/drive'     # default for the drive\n","drive.mount(ROOT, force_remount=True)\n","os.chdir(\"/content/drive/My Drive/BACMMAN_DISTNET\")\n","\n","# install/load packages\n","!pip install git+https://github.com/jeanollion/dataset_iterator.git\n","# !pip install git+https://github.com/hugovaysset/uad.git\n","import tensorflow as tf\n","import h5py\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from uad.models.variational_autoencoder import VAE  # package not found when install from github\n","from tensorflow.keras import layers, Model\n","\n","# copy data locallly\n","dataset_dir = f\"{ROOT}/My Drive/BACMMAN_DISTNET/data/BACMMAN/\"\n","!cp \"/content/drive/My Drive/BACMMAN_DISTNET/data/BACMMAN/train_val_eval.h5\" \"/home/train_val_eval.h5\"\n","dataset_path = \"/home/train_val_eval.h5\"\n","print(dataset_path)\n","\n","!nvidia-smi"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Collecting git+https://github.com/jeanollion/dataset_iterator.git\n","  Cloning https://github.com/jeanollion/dataset_iterator.git to /tmp/pip-req-build-_g6jvukk\n","  Running command git clone -q https://github.com/jeanollion/dataset_iterator.git /tmp/pip-req-build-_g6jvukk\n","Requirement already satisfied (use --upgrade to upgrade): dataset-iterator==0.0.1 from git+https://github.com/jeanollion/dataset_iterator.git in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: h5py>=2.9 in /usr/local/lib/python3.6/dist-packages (from dataset-iterator==0.0.1) (2.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dataset-iterator==0.0.1) (1.18.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from dataset-iterator==0.0.1) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from dataset-iterator==0.0.1) (0.22.2.post1)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from dataset-iterator==0.0.1) (2.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py>=2.9->dataset-iterator==0.0.1) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->dataset-iterator==0.0.1) (0.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (1.1.0)\n","Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (2.2.2)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (1.30.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (0.34.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (1.12.1)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (3.12.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (0.9.0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (0.2.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (0.3.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (3.3.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (1.6.3)\n","Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dataset-iterator==0.0.1) (2.2.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (49.1.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (1.7.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (3.2.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (0.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (2.23.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (1.17.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (1.7.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (1.3.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (2020.6.20)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (4.1.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (0.2.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (3.1.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->dataset-iterator==0.0.1) (0.4.8)\n","Building wheels for collected packages: dataset-iterator\n","  Building wheel for dataset-iterator (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dataset-iterator: filename=dataset_iterator-0.0.1-cp36-none-any.whl size=35945 sha256=dcd599b51664ce0c54a00df3a22a7ccd63afc3f00f0da773fb312c72de116447\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-83rmhveh/wheels/e1/b1/4a/efb8888afaa53e058db8520c203e13af93ca10b2a8d42ab098\n","Successfully built dataset-iterator\n","/home/train_val_eval.h5\n","Tue Jul 28 16:45:53 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yteeyvESSDBZ","colab_type":"text"},"source":["## Load datasets"]},{"cell_type":"code","metadata":{"id":"vVtyx8WAR1mH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595961024897,"user_tz":-120,"elapsed":1825,"user":{"displayName":"H V","photoUrl":"","userId":"04112076308917049663"}},"outputId":"a9f05743-b780-406b-a072-9af717216062"},"source":["from dataset_iterator import MultiChannelIterator, PreProcessingImageGenerator\n","\n","image_scaling = PreProcessingImageGenerator(lambda im:im/(2**16 - 1)) # simple scaling of 8-bit images -> data in [0, 1]\n","\n","x_train = MultiChannelIterator(dataset=dataset_path, \n","                                channel_keywords=[\"/raw\"],\n","                                group_keyword = \"train\", \n","                                input_channels=[0],\n","                                output_channels=[0], \n","                                image_data_generators=[image_scaling],\n","                                batch_size=1\n","                                )\n","\n","x_val = MultiChannelIterator(dataset=dataset_path, \n","                                channel_keywords=[\"/raw\"],\n","                                group_keyword = \"val\",\n","                                input_channels=[0],\n","                                output_channels=[0], \n","                                image_data_generators=[image_scaling],\n","                                batch_size=1\n","                                )\n","\n","x_test = MultiChannelIterator(dataset=dataset_path, \n","                                channel_keywords=[\"/raw\"],\n","                                group_keyword = \"eval\",\n","                                input_channels=[0],\n","                                output_channels=[0], \n","                                image_data_generators=[image_scaling],\n","                                batch_size=1\n","                                )\n","\n","print(f\"Number of batches {len(x_train)} of size {len(x_train[0][0])}\")"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Number of batches 9868 of size 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sIXGHzuQnhp4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595959902154,"user_tz":-120,"elapsed":4950,"user":{"displayName":"H V","photoUrl":"","userId":"04112076308917049663"}},"outputId":"65960e1d-7dea-48f0-f29e-d5dbbd1ea46e"},"source":["for i in range(len(x_train)):\n","    if len(x_train[i][0]) != 64:\n","        print(i, len(x_train[i][0]))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["154 12\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wceB5tI_Snmc","colab_type":"text"},"source":["## Build model"]},{"cell_type":"code","metadata":{"id":"QH7_RCfmSiVI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595958381695,"user_tz":-120,"elapsed":984,"user":{"displayName":"H V","photoUrl":"","userId":"04112076308917049663"}}},"source":["class Sampling(layers.Layer):\n","    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var = inputs\n","        batch = tf.shape(z_mean)[0]\n","        dim1, dim2, dim3 = tf.shape(z_mean)[1], tf.shape(z_mean)[2], tf.shape(z_mean)[3]\n","        epsilon = tf.keras.backend.random_normal(shape=(batch, dim1, dim2, dim3))\n","        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n","\n","\n","def conv2d_block(input_tensor, n_filters, kernel_size=(3, 1), batchnorm=True, activation1=\"relu\",\n","                 activation2=\"sigmoid\"):\n","    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\n","    activation1: name of the activation function to apply. If none, pass \"\" (empty string)\n","    activation2: name of the activation function to apply. If none, pass \"\" (empty string)\n","    \"\"\"\n","    # first layer\n","    x = layers.Conv2D(filters=n_filters, kernel_size=kernel_size, \n","                      kernel_initializer='he_normal', padding='same')(input_tensor)\n","    if batchnorm:\n","        x = layers.BatchNormalization()(x)\n","    if activation1 != \"\":\n","        x = layers.Activation(activation1)(x)\n","\n","    # second layer\n","    x = layers.Conv2D(filters=n_filters, kernel_size=kernel_size, \n","                      kernel_initializer='he_normal', padding='same')(input_tensor)\n","    if batchnorm:\n","        x = layers.BatchNormalization()(x)\n","    if activation2 != \"\":\n","        x = layers.Activation(activation2)(x)\n","\n","    return x\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"tP1_8OpMTBJ2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595958393892,"user_tz":-120,"elapsed":8967,"user":{"displayName":"H V","photoUrl":"","userId":"04112076308917049663"}}},"source":["n_filters = 16\n","n_contractions = 5\n","latent_depth = n_filters * int(2**n_contractions)\n","latent_dims = (int(256 / (2**n_contractions)), int(32 / (2**n_contractions)), latent_depth)\n","batchnorm, dropout = False, 0.2\n","k_size = (3, 1)\n","\n","encoder_inputs = layers.Input(shape=(256, 32, 1), name=\"encoder_inputs\")\n","\n","# contracting path\n","for i in range(n_contractions):\n","    if i == 0:\n","        x = conv2d_block(encoder_inputs, n_filters * 2**i, kernel_size=k_size, \n","                         batchnorm=batchnorm)\n","    else:\n","        x = conv2d_block(x, n_filters * 2**i, kernel_size=k_size, batchnorm=batchnorm)\n","    x = layers.MaxPooling2D((2, 2))(x)\n","    x = layers.Dropout(dropout)(x)\n","\n","z_mean = layers.Conv2D(latent_depth, 1, strides=1, name=\"z_mean\")(x)\n","z_log_var = layers.Conv2D(latent_depth, 1, strides=1, name=\"z_log_var\")(x)\n","z = Sampling()((z_mean, z_log_var))\n","\n","encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n","\n","# Define decoder model.\n","latent_inputs = layers.Input(shape=latent_dims, name=\"z_sampling\")\n","\n","for i in range(n_contractions - 1, 0, -1):\n","    if i == n_contractions - 1:\n","        x = layers.Conv2DTranspose(n_filters * 2**i, k_size, strides=(2, 2), \n","                                   padding='same')(latent_inputs)\n","    else:\n","        x = layers.Conv2DTranspose(n_filters * 2**i, k_size, strides=(2, 2), \n","                                   padding='same')(x)\n","    x = layers.Dropout(dropout)(x)\n","    x = conv2d_block(x, n_filters * 2**i, kernel_size=k_size, batchnorm=batchnorm)\n","\n","x = layers.Conv2DTranspose(n_filters * 2**i, kernel_size=k_size, strides=(2, 2), \n","                            padding='same')(x)\n","x = layers.Dropout(dropout)(x)\n","x = layers.Conv2D(1, kernel_size=k_size, padding=\"same\")(x)\n","\n","\n","decoder = Model(inputs=latent_inputs, outputs=x, name=\"decoder\")\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-uW2m91Yye6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595958610575,"user_tz":-120,"elapsed":1341,"user":{"displayName":"H V","photoUrl":"","userId":"04112076308917049663"}}},"source":["class VAE(Model):\n","    \"\"\"\n","    Variational autoencoder without predefined architecture. Build the encoder and decoder\n","    using the keras functional API and pass them as arguments to the class to instantiate\n","    a custom VAE model.\n","    \"\"\"\n","\n","    def __init__(self, encoder, decoder, dims=(28, 28, 1), reconstruction_loss=\"mse\", **kwargs):\n","        \"\"\"\n","        :param encoder:\n","        :param decoder:\n","        :param dims:\n","        :param reconstruction_loss: name of the reconstruction loss to use (can be \"xent\" for MNIST or \"mse\" for real\n","        images\n","        \"\"\"\n","        super(VAE, self).__init__(**kwargs)\n","        self.dims = dims\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.reconstruction_loss = reconstruction_loss\n","\n","    def train_step(self, data):\n","        if isinstance(data, tuple):\n","            data = data[0]\n","\n","        with tf.GradientTape() as tape:\n","\n","            z_mean, z_log_var, z = self.encoder(data)\n","            reconstruction = self.decoder(z)\n","\n","            if self.reconstruction_loss == \"xent\":\n","                reconstruction_loss = tf.reduce_mean(\n","                    tf.keras.losses.binary_crossentropy(data, reconstruction)\n","                )\n","                reconstruction_loss *= self.dims[0] * self.dims[1]\n","            elif self.reconstruction_loss == \"mse\":\n","                reconstruction_loss = tf.keras.losses.MSE(data, reconstruction)\n","            else:\n","                raise NotImplementedError(\"Reconstruction loss should be either xent or mse\")\n","            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n","            kl_loss = tf.reduce_mean(kl_loss)\n","            kl_loss *= -0.5\n","            total_loss = reconstruction_loss + kl_loss\n","\n","        grads = tape.gradient(total_loss, self.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","        \n","        return {\n","            \"loss\": total_loss,\n","            \"reconstruction_loss\": reconstruction_loss,\n","            \"kl_loss\": kl_loss,\n","        }\n","\n","    def test_step(self, data):\n","        if isinstance(data, tuple):\n","            data = data[0]\n","\n","        with tf.GradientTape() as tape:\n","            z_mean, z_log_var, z = self.encoder(data)\n","            reconstruction = self.decoder(z)\n","\n","            if self.reconstruction_loss == \"xent\":\n","                reconstruction_loss = tf.reduce_mean(\n","                    tf.keras.losses.binary_crossentropy(data, reconstruction)\n","                )\n","                reconstruction_loss *= self.dims[0] * self.dims[1]\n","            elif self.reconstruction_loss == \"mse\":\n","                reconstruction_loss = tf.keras.losses.MSE(data, reconstruction)\n","            else:\n","                raise NotImplementedError(\"Reconstruction loss should be either xent or mse\")\n","            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n","            kl_loss = tf.reduce_mean(kl_loss)\n","            kl_loss *= -0.5\n","            total_loss = reconstruction_loss + kl_loss\n","\n","        return {\n","            \"loss\": total_loss,\n","            \"reconstruction_loss\": reconstruction_loss,\n","            \"kl_loss\": kl_loss,\n","        }\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var, z = self.encoder(inputs)\n","        return self.decoder(z)\n","\n","vae = VAE(encoder, decoder, dims=(256, 32, 1), reconstruction_loss=\"mse\")\n","\n","vae.compile(optimizer=tf.keras.optimizers.Adam())"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"9U4oqA7fezm1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":400},"executionInfo":{"status":"ok","timestamp":1595961253479,"user_tz":-120,"elapsed":165989,"user":{"displayName":"H V","photoUrl":"","userId":"04112076308917049663"}},"outputId":"56b79dbc-80b0-4525-8c6b-77bb26f9bcbf"},"source":["epochs = 10\n","batch_size = 64\n","\n","history = vae.fit_generator(x_train, validation_data=x_val, steps_per_epoch=len(x_train) // batch_size,\n","\tepochs=epochs)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","154/154 [==============================] - 17s 111ms/step - loss: 0.0084 - reconstruction_loss: 0.0084 - kl_loss: 3.2664e-07 - val_loss: 4.7809e-05 - val_reconstruction_loss: 4.7809e-05 - val_kl_loss: -1.6735e-10\n","Epoch 2/10\n","154/154 [==============================] - 17s 107ms/step - loss: 4.3124e-05 - reconstruction_loss: 4.3123e-05 - kl_loss: 1.2368e-09 - val_loss: 4.3621e-05 - val_reconstruction_loss: 4.3619e-05 - val_kl_loss: 1.3533e-09\n","Epoch 3/10\n","154/154 [==============================] - 16s 104ms/step - loss: 3.8789e-05 - reconstruction_loss: 3.8788e-05 - kl_loss: 1.6477e-09 - val_loss: 3.8865e-05 - val_reconstruction_loss: 3.8863e-05 - val_kl_loss: 1.7972e-09\n","Epoch 4/10\n","154/154 [==============================] - 17s 110ms/step - loss: 3.6230e-05 - reconstruction_loss: 3.6228e-05 - kl_loss: 1.6450e-09 - val_loss: 3.4679e-05 - val_reconstruction_loss: 3.4677e-05 - val_kl_loss: 2.0445e-09\n","Epoch 5/10\n","154/154 [==============================] - 16s 105ms/step - loss: 3.2127e-05 - reconstruction_loss: 3.2126e-05 - kl_loss: 1.6620e-09 - val_loss: 2.7090e-05 - val_reconstruction_loss: 2.7088e-05 - val_kl_loss: 1.7826e-09\n","Epoch 6/10\n","154/154 [==============================] - 16s 102ms/step - loss: 3.0918e-05 - reconstruction_loss: 3.0916e-05 - kl_loss: 1.7505e-09 - val_loss: 3.2549e-05 - val_reconstruction_loss: 3.2548e-05 - val_kl_loss: 1.5643e-09\n","Epoch 7/10\n","154/154 [==============================] - 17s 108ms/step - loss: 2.9142e-05 - reconstruction_loss: 2.9140e-05 - kl_loss: 1.7883e-09 - val_loss: 2.7467e-05 - val_reconstruction_loss: 2.7465e-05 - val_kl_loss: 1.6080e-09\n","Epoch 8/10\n","154/154 [==============================] - 16s 105ms/step - loss: 2.8143e-05 - reconstruction_loss: 2.8141e-05 - kl_loss: 1.7636e-09 - val_loss: 2.3311e-05 - val_reconstruction_loss: 2.3310e-05 - val_kl_loss: 1.4479e-09\n","Epoch 9/10\n","154/154 [==============================] - 16s 103ms/step - loss: 2.6890e-05 - reconstruction_loss: 2.6888e-05 - kl_loss: 1.7616e-09 - val_loss: 1.9713e-05 - val_reconstruction_loss: 1.9711e-05 - val_kl_loss: 1.8917e-09\n","Epoch 10/10\n","154/154 [==============================] - 18s 114ms/step - loss: 2.5548e-05 - reconstruction_loss: 2.5546e-05 - kl_loss: 1.4551e-09 - val_loss: 2.8612e-05 - val_reconstruction_loss: 2.8610e-05 - val_kl_loss: 1.2224e-09\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GMp64rh7e_zf","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}